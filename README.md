# Songs Log ETL 

### Abstract
The Sparkify startup  wants to analyze the data they've been collecting on songs and user activity on their new music streaming app. The analytics team is particularly interested in understanding what songs users are listening to. Currently, they don't have an easy way to query their data, which resides in a directory of JSON logs on user activity on the app, as well as a directory with JSON metadata on the songs in their app.

This project creates a Postgres database with tables designed to optimize queries on song play analysis. Specifically, it creates a database schema in star configuration and an ETL pipeline for this analysis. The ETL pipeline  transfers data from files in two local directories into the Postgres tables using Python and SQL.

#### Logs Dataset 
The activity logs from the music streaming app are in log files in JSON format.

The log files in the dataset are partitioned by year and month. For example, here are filepaths to two files in this dataset:
```
data/log_data/2018/11/2018-11-12-events.json
data/log_data/2018/11/2018-11-13-events.json
```
File format:
```
{
    "artist":"Taylor Swift",
    "auth":"Logged In",
    "firstName":"Tegan",
    "gender":"F",
    "itemInSession":4,
    "lastName":"Levine",
    "length":238.99383,
    "level":"paid",
    "location":"Portland-South Portland, ME",
    "method":"PUT",
    "page":"NextSong",
    "registration":1540794356796.0,
    "sessionId":481,
    "song":"Cold As You",
    "status":200,
    "ts":1542061558796,
    "userAgent":"\"Mozilla\/5.0 (Macintosh; Intel Mac OS X 10_9_4) AppleWebKit\/537.36 (KHTML, like Gecko) Chrome\/36.0.1985.143 Safari\/537.36\"",
    "userId":"80"
}
```
> The log files have been generated by Eventsim, a program that generates event data for testing and demos. 
https://github.com/Interana/eventsim

### Songs Dataset
The dataset is a subset of real data from the Million Song Dataset http://millionsongdataset.com/. Each file is in JSON format and contains metadata about a song and the artist of that song. The files are partitioned by the first three letters of each song's track ID. 

For example, here are filepaths to two files in this dataset:
data/song_data/A/B/C/TRABCEI128F424C983.json
data/ song_data/A/A/B/TRAABJL12903CDCF1A.json

Below is the format of a single song file:
```
{
    "num_songs":1,
    "artist_id":"ARJIE2Y1187B994AB7",
    "artist_latitude":null,
    "artist_longitude":null,
    "artist_location":"",
    "artist_name":"Line Renaud",
    "song_id":"SOUPIRU12A6D4FA1E1",
    "title":"Der Kleine Dompfaff",
    "duration":152.92036,
    "year":0
}
```

#### Schema for Song Play Analysis
The database schema is optimized for queries on song play analysis and it follows the `star` style. It includes the following tables:

##### Fact Table
`songplays` - records in log data associated with song plays (i.e. records with page value NextSong)

##### Dimension Tables
`users` - users in the app
`songs` - songs in music database
`artists` - artists in music database
`time` - timestamps of records in songplays broken down into specific units

#### ETL Process

1. Build the `sparkifydb` database running `create_tables.py`
2. Check the tables with `psql postgres`
3. Run the ETL process to load the database with `etl.py`

>Since we are testing with a subset of a much larger dataset, the `songplays` fact table will only have 1 row with not null values for both `songid` and `artistid` in the table.

#### Tools used
##### For the ER diagram
1. Generate the schema
    `$ pg_dump -s sparkifydb > sparkifydb-schema.sql`
https://www.postgresql.org/docs/8.4/app-pgdump.html
2. upload the schema to https://dbdiagram.io/
3. export PDF and PNG

#### Useful Links
* Install Postgres on Mac:
https://www.codementor.io/@engineerapart/getting-started-with-postgresql-on-mac-osx-are8jcopb
* To use `sql` in ipython under a conda environment:
https://anaconda.org/conda-forge/ipython-sql
* PostgreSQL Upsert Using INSERT ON CONFLICT statement:
https://www.postgresqltutorial.com/postgresql-upsert/
* PostgreSQL constraints:
https://www.postgresql.org/docs/9.4/ddl-constraints.html
* PostgreSQL numeric types:
https://www.postgresql.org/docs/8.3/datatype-numeric.html
* `psql postgres` cheat sheet:
https://gist.github.com/Kartones/dd3ff5ec5ea238d4c546
